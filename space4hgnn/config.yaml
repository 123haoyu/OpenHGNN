node_classification:
  HGBn-ACM:
    homo_GNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        gcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
    relation_HGNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        rgcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    mp_GNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        hanconv
      macro_func:
        attention

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    GCN:
      hidden_dim:
        64
      num_layers:
        2
      dropout:
        0.5
      lr:
        0.0005
      weight_decay:
        0.0001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
      activation:
        relu
    GAT:
      hidden_dim:
        64
      num_layers:
        2
      dropout:
        0.5
      slope:
        0.05
      num_heads:
        8
      lr:
        0.0005
      weight_decay:
        0.0001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
  HGBn-DBLP:
    homo_GNN:
      hidden_dim:
        64
      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      activation:
        relu
      dropout:
        0.5
      has_l2norm:
        False
      has_bn:
        True
      stage_type:
        skipsum
      gnn_type:
        gcnconv
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False


    mp_GNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        hanconv
      macro_func:
        attention

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    relation_HGNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        rgcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    GCN:
      hidden_dim:
        64
      num_layers:
        2
      dropout:
        0.5
      lr:
        0.0005
      weight_decay:
        0.0001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
      activation:
        relu
  HGBn-Freebase:
    homo_GNN:
      hidden_dim:
        64
      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        2
      activation:
        relu
      dropout:
        0.5
      has_l2norm:
        False
      has_bn:
        False
      stage_type:
        stack
      gnn_type:
        gcnconv
      lr:
        0.001
      weight_decay:
        0.0001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    relation_HGNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        rgcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
    mp_GNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        hanconv
      macro_func:
        attention

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
  HGBn-IMDB:
    homo_GNN:
      hidden_dim:
        64
      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        2
      activation:
        relu
      dropout:
        0.5
      has_l2norm:
        False
      has_bn:
        False
      stage_type:
        stack
      gnn_type:
        gcnconv
      lr:
        0.001
      weight_decay:
        0.0001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    mp_GNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        hanconv
      macro_func:
        attention

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

    relation_HGNN:
      hidden_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        rgcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False

link_prediction:
  HGBl-amazon:
    homo_GNN:
      hidden_dim:
        64
      out_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        gcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
      node_type:
        - product
      test_edge_type:
        product-product-0:
          0
        product-product-1:
          1

  HGBl-PubMed:
    homo_GNN:
      hidden_dim:
        64
      out_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        gcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
      node_type:
        - "0"
        - "1"
        - "2"
        - "3"
      test_edge_type:
        1_to_1:
          2

  HGBl-LastFM:
    homo_GNN:
      hidden_dim:
        64
      out_dim:
        64

      layers_pre_mp:
        1
      layers_post_mp:
        1
      layers_gnn:
        3
      stage_type:
        stack

      activation:
        relu
      dropout:
        0.5
      has_bn:
        False
      gnn_type:
        gcnconv

      has_l2norm:
        False
      lr:
        0.001
      weight_decay:
        0.000001
      patience:
        30
      max_epoch:
        300
      mini_batch_flag:
        False
      node_type:
        - user
        - artist
        - tag
      test_edge_type:
        user-artist:
          0